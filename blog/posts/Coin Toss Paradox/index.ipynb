{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f929e0f9-6658-4ce1-a018-c324b52b1980",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"A Coin Mixture Paradox: The Interesting Case of Constant Variance\"\n",
    "author: \"Emil Blaignan\"\n",
    "date: \"2025-04-03\"\n",
    "categories: [Bayesian Statistics, Probability]\n",
    "toc: true\n",
    "toc-depth: 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f9f53-b4d0-4f62-b001-b71a0ccffa61",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](coin_paradox_thumbnail.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d922f-0c4a-4718-80e4-fe66a9b2c286",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db4a33-4754-4bf8-ae2a-463348d56358",
   "metadata": {},
   "source": [
    "Recently, in my stochastic processes discussion, we went over a coin-flipping problem. In my probability course, we’ve covered many coin-toss problems, but I found this particular problem especially interesting—so much so that it sent me down a rabbit hole trying to understand it. The problem went as follows:\n",
    "\n",
    "**Imagine you have two coins. One is perfectly fair (50% chance of heads), and the other is biased, with a 60% chance of heads. Visually, the coins are indistinguishable. We then flip the left coin twice (not knowing if it is fair or biased), thus what is the variance of the number of heads denoted by $\\text{Var}(\\text{\\# heads})$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dcc4e3-1cdd-434d-9dfc-8686346fc15a",
   "metadata": {},
   "source": [
    "## Coin Flip Variance Solution\n",
    "\n",
    "The solution goes as follows: \n",
    "\n",
    "Let  \n",
    "$$\n",
    "X = X_1 + X_2\n",
    "$$  \n",
    "where $X_1$ and $X_2$ represent the results of the first and second coin flips, respectively (1 = heads, 0 = tails).\n",
    "\n",
    "We want to compute:\n",
    "$$\n",
    "\\operatorname{Var}(X) = \\operatorname{Var}(X_1 + X_2)\n",
    "$$\n",
    "\n",
    "Using the identity:\n",
    "$$\n",
    "\\operatorname{Var}(X_1 + X_2) = \\operatorname{Var}(X_1) + \\operatorname{Var}(X_2) + 2 \\cdot \\operatorname{Cov}(X_1, X_2)\n",
    "$$\n",
    "\n",
    "> *Note: The two coin flips are **not independent**, since flipping one head increases the likelihood that the coin is biased. Hence, we must account for covariance.*\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Compute $\\operatorname{Var}(X_1)$\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}(X_1) = \\mathbb{E}[X_1^2] - (\\mathbb{E}[X_1])^2\n",
    "$$\n",
    "\n",
    "Since $X_1 \\in \\{0, 1\\}$ (Bernoulli random variable), $X_1^2 = X_1$, so:\n",
    "$$\n",
    "\\mathbb{E}[X_1^2] = \\mathbb{E}[X_1]\n",
    "$$\n",
    "\n",
    "We compute $\\mathbb{E}[X_1]$ using the law of total expectation:\n",
    "$$\n",
    "\\mathbb{E}[X_1] = \\mathbb{P}(\\text{Heads}) = \\frac{1}{2}(0.5) + \\frac{1}{2}(0.6) = 0.55\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}(X_1) = 0.55 - (0.55)^2 = 0.55 - 0.3025 = 0.2475\n",
    "$$\n",
    "\n",
    "By symmetry:\n",
    "$$\n",
    "\\operatorname{Var}(X_2) = \\operatorname{Var}(X_1) = 0.2475\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Compute $\\operatorname{Cov}(X_1, X_2)$\n",
    "\n",
    "We use:\n",
    "$$\n",
    "\\operatorname{Cov}(X_1, X_2) = \\mathbb{E}[X_1 X_2] - \\mathbb{E}[X_1]\\mathbb{E}[X_2]\n",
    "$$\n",
    "\n",
    "#### Compute $\\mathbb{E}[X_1 X_2]$\n",
    "\n",
    "This is the probability that both flips are heads:\n",
    "$$\n",
    "\\mathbb{P}(\\text{both H}) = \\mathbb{P}(\\text{both H} \\mid \\text{fair}) \\cdot \\mathbb{P}(\\text{fair}) + \\mathbb{P}(\\text{both H} \\mid \\text{biased}) \\cdot \\mathbb{P}(\\text{biased})\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (0.5)(0.5)^2 + (0.5)(0.6)^2 = 0.5(0.25) + 0.5(0.36) = 0.125 + 0.18 = 0.305\n",
    "$$\n",
    "\n",
    "#### Compute $\\mathbb{E}[X_1]\\mathbb{E}[X_2]$\n",
    "\n",
    "$$\n",
    "= (0.55)^2 = 0.3025\n",
    "$$\n",
    "\n",
    "So,\n",
    "$$\n",
    "\\operatorname{Cov}(X_1, X_2) = 0.305 - 0.3025 = 0.0025\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Final Step: Combine All\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}(X) = \\operatorname{Var}(X_1) + \\operatorname{Var}(X_2) + 2 \\cdot \\operatorname{Cov}(X_1, X_2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 0.2475 + 0.2475 + 2(0.0025) = 0.495 + 0.005 = \\boxed{0.5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c274b910-8804-492c-8ae7-57836b4eaa89",
   "metadata": {},
   "source": [
    "## Interpretting Our Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8fa11-9135-4144-9e64-24e63bfe77fc",
   "metadata": {},
   "source": [
    "I don’t know about you, but I found it hard to believe that the answer was actually 1/2. \n",
    "\n",
    "For example, we know: \n",
    "\n",
    "- A fair coin (p=0.5) flipped twice has variance 0.5\n",
    "- A biased coin (p=0.6) flipped twice has variance 0.48\n",
    "- We have a 50/50 chance of using either coin\n",
    "\n",
    "We can also graph the relationship of variance to probability of heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d79c44-f0e2-4841-a3f5-02d090a24840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default=\"iframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e1125e1-1d16-43ad-9e41-d5f2a2e61fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_9.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Number of coin flips\n",
    "n = 2\n",
    "\n",
    "# Create an array of probability values from 0 to 1\n",
    "p_values = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Calculate variance for each probability value\n",
    "# For binomial distribution: Var(X) = n * p * (1-p)\n",
    "variances = n * p_values * (1 - p_values)\n",
    "\n",
    "# Create a plotly figure\n",
    "fig = make_subplots()\n",
    "\n",
    "# Add the main curve\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=p_values,\n",
    "        y=variances,\n",
    "        mode='lines',\n",
    "        name='Variance',\n",
    "        line=dict(color='blue', width=3),\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(0, 0, 255, 0.1)',\n",
    "        hovertemplate='Probability: %{x:.3f}<br>Variance: %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add points for p=0.5 (fair coin) and p=0.6 (biased coin)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5],\n",
    "        y=[n * 0.5 * 0.5],\n",
    "        mode='markers+text',\n",
    "        name='Fair coin (p=0.5)',\n",
    "        marker=dict(color='red', size=12),\n",
    "        text=[\"Fair coin\"],\n",
    "        textposition=\"top center\",\n",
    "        hovertemplate='Fair coin<br>Probability: 0.5<br>Variance: 0.5<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.6],\n",
    "        y=[n * 0.6 * 0.4],\n",
    "        mode='markers+text',\n",
    "        name='Biased coin (p=0.6)',\n",
    "        marker=dict(color='green', size=12),\n",
    "        textposition=\"top center\",\n",
    "        hovertemplate='Biased coin<br>Probability: 0.6<br>Variance: %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add a point for maximum variance at p=0.5\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5],\n",
    "        y=[0.5],\n",
    "        mode='text',\n",
    "        textposition=\"top center\",\n",
    "        showlegend=False,\n",
    "        hoverinfo='none'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title='Variance of Number of Heads in Two Coin Flips',\n",
    "    xaxis_title='Probability of Heads (p)',\n",
    "    yaxis_title='Variance',\n",
    "    xaxis=dict(range=[0, 1], tickformat='.1f'),\n",
    "    yaxis=dict(range=[0, 0.6]),\n",
    "    hovermode='closest',\n",
    "    legend=dict(x=0.02, y=0.98),\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "# Add grid lines\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "\n",
    "# Add a horizontal line at y=0\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=0,\n",
    "    y0=0,\n",
    "    x1=1,\n",
    "    y1=0,\n",
    "    line=dict(color=\"black\", width=1, dash=\"solid\"),\n",
    ")\n",
    "\n",
    "# Add annotations for key values\n",
    "annotations = [\n",
    "    dict(\n",
    "        x=0, \n",
    "        y=0, \n",
    "        xref=\"x\", \n",
    "        yref=\"y\",\n",
    "        text=\"Var = 0 at p=0\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        ax=40,\n",
    "        ay=40\n",
    "    ),\n",
    "    dict(\n",
    "        x=1, \n",
    "        y=0, \n",
    "        xref=\"x\", \n",
    "        yref=\"y\",\n",
    "        text=\"Var = 0 at p=1\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        ax=-40,\n",
    "        ay=40\n",
    "    )\n",
    "]\n",
    "fig.update_layout(annotations=annotations)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219b5c9-93da-49e6-a3bc-b8b92ac44939",
   "metadata": {},
   "source": [
    "So, kind of like a magic trick, how is it possible that with a biased coin, our variance is the same as if we flipped two fair coins?\n",
    "\n",
    "The answer is actually in the wording of the problem. By adding the uncertainty about which coin we're using (we picked the left coin not knowing whether it's fair or biased), we perfectly compensate for the reduced variance of the biased coin. On top of that, it wouldn't matter whether the probability of heads was 0.6 or 0.7 or 0.8. For any probability of heads for the biased coin, our variance of heads for the two coin flips will always be 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114256ff-fdb2-436a-b273-f7bef11e2a93",
   "metadata": {},
   "source": [
    "It was at this point that I left the discussion knowing the answer to the paradox, however, I still wasn’t fully convinced. Thus, as any curious mathematician would do, I sought to understand why our solution works the way it does by generalizing the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21752c0d-77b5-4c9f-8162-59b1577df049",
   "metadata": {},
   "source": [
    "## Generalizing the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b4f37-d1d3-4ea8-b6d9-26622e503896",
   "metadata": {},
   "source": [
    "**Imagine you have two coins. One is perfectly fair (50% chance of heads), and the other is biased, but you don't necessarily know its exact bias – just that it has some probability *p* of landing heads.**\n",
    "\n",
    "Now, consider this experiment:\n",
    "\n",
    "1. You randomly pick one of the two coins (with equal probability, 0.5 each).\n",
    "2. You flip the *chosen* coin twice.\n",
    "3. You count the total number of heads, let's call this *Y*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c4e37f-5a6e-4f6d-874c-ff01273a444d",
   "metadata": {},
   "source": [
    "Let's define our variables more formally:\n",
    "\n",
    "- $C$: The random variable representing the chosen coin.\n",
    "    * $C = F$ (Fair coin) with $P(C=F) = 0.5$\n",
    "    * $C = B$ (Biased coin) with $P(C=B) = 0.5$\n",
    "- Probabilities of Heads:\n",
    "    * $P(\\text{Heads} | C=F) = p_F = 0.5$\n",
    "    * $P(\\text{Heads} | C=B) = p_B = p$ (where $0 \\leq p \\leq 1$)\n",
    "- **$X_1, X_2$**: The outcomes of the two flips (1 for heads, 0 for tails). These are Bernoulli trials *given* the chosen coin.\n",
    "- **$Y$**: The total number of heads in the two flips. $Y = X_1 + X_2$. *Given* the coin, $Y$ follows a Binomial distribution $\\text{Bin}(n=2, \\text{probability}=p_C)$.\n",
    "\n",
    "Our goal is to calculate $\\text{Var}(Y)$, the variance of the total number of heads *before* we know which coin was chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b72d6b-f54d-4977-acea-d4415f671694",
   "metadata": {},
   "source": [
    "### Explaining the Constant Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fbcecc-12d9-47f9-8e35-7a949f27ee0f",
   "metadata": {},
   "source": [
    "The key to understanding this result lies in the **Law of Total Variance** (also known as Eve's Law). For random variables $Y$ and $C$, it states:\n",
    "\n",
    "$$\\text{Var}(Y) = E[\\text{Var}(Y | C)] + \\text{Var}(E[Y | C])$$\n",
    "\n",
    "Let's break this down:\n",
    "\n",
    "1. **$E[\\text{Var}(Y | C)]$**: The *expected value of the conditional variance*. This is the average variance *within* each coin type. We calculate the variance of $Y$ *assuming* we know which coin was picked ($\\text{Var}(Y | C=F)$ and $\\text{Var}(Y | C=B)$) and then find the weighted average of these variances based on the probability of picking each coin.\n",
    "\n",
    "2. **$\\text{Var}(E[Y | C])$**: The *variance of the conditional expectation*. This measures the variability *between* the average outcomes of the different coin types. We calculate the expected value of $Y$ *assuming* we know which coin was picked ($E[Y | C=F]$ and $E[Y | C=B]$) and then find the variance of these expected values, treating $E[Y | C]$ itself as a random variable that depends on $C$.\n",
    "\n",
    "Let's calculate each term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364def7-2ed1-4e70-91d7-daf5342af0d3",
   "metadata": {},
   "source": [
    "### Step 1: Conditional Expectations and Variances\n",
    "\n",
    "First, let's find the expected value and variance of $Y$, *conditional* on knowing which coin was chosen.\n",
    "\n",
    "* **Given the Fair Coin ($C=F$):**\n",
    "    * The number of heads $Y$ follows $\\text{Bin}(n=2, p=0.5)$.\n",
    "    * $E[Y | C=F] = n \\cdot p_F = 2 \\times 0.5 = 1$\n",
    "    * $\\text{Var}(Y | C=F) = n \\cdot p_F \\cdot (1 - p_F) = 2 \\cdot 0.5 \\cdot (1 - 0.5) = 2 \\cdot 0.5 \\times 0.5 = 0.5$\n",
    "* **Given the Biased Coin ($C=B$):**\n",
    "    * The number of heads $Y$ follows $\\text{Bin}(n=2, p=p)$.\n",
    "    * $E[Y | C=B] = n \\cdot p_B = 2 \\times p$\n",
    "    * $\\text{Var}(Y | C=B) = n \\cdot p_B \\cdot (1 - p_B) = 2 \\cdot p \\times (1 - p) = 2p(1-p)$\n",
    "\n",
    "### Step 2: Calculate $E[\\text{Var}(Y | C)]$\n",
    "\n",
    "This is the average of the conditional variances, weighted by the probability of choosing each coin:\n",
    "\n",
    "$$E[\\text{Var}(Y | C)] = \\text{Var}(Y | C=F) \\cdot P(C=F) + \\text{Var}(Y | C=B) \\cdot P(C=B)$$\n",
    "\n",
    "$$E[\\text{Var}(Y | C)] = (0.5) \\cdot (0.5) + (2p(1-p)) \\cdot (0.5)$$\n",
    "\n",
    "$$E[\\text{Var}(Y | C)] = 0.25 + p(1-p)$$\n",
    "\n",
    "$$E[\\text{Var}(Y | C)] = 0.25 + p - p^2$$\n",
    "\n",
    "### Step 3: Calculate $\\text{Var}(E[Y | C])$\n",
    "\n",
    "This is the variance of the conditional means. We have a random variable $E[Y | C]$ which takes the value $E[Y | C=F] = 1$ with probability 0.5, and the value $E[Y | C=B] = 2p$ with probability 0.5.\n",
    "\n",
    "To find its variance, we use $\\text{Var}(X) = E[X^2] - (E[X])^2$.\n",
    "\n",
    "* First, find the mean $E[E[Y | C]]$:\n",
    "\n",
    "    $$E[E[Y | C]] = E[Y | C=F] \\cdot P(C=F) + E[Y | C=B] \\cdot P(C=B)$$\n",
    "    \n",
    "    $$E[E[Y | C]] = (1) \\cdot (0.5) + (2p) \\cdot (0.5)$$\n",
    "    \n",
    "    $$E[E[Y | C]] = 0.5 + p$$\n",
    "    \n",
    "    *(Note: By the law of total expectation, this is also $E[Y]$).*\n",
    "\n",
    "* Next, find the expected value of the square $E[(E[Y | C])^2]$:\n",
    "\n",
    "    $$E[(E[Y | C])^2] = (E[Y | C=F])^2 \\cdot P(C=F) + (E[Y | C=B])^2 \\cdot P(C=B)$$\n",
    "    \n",
    "    $$E[(E[Y | C])^2] = (1)^2 \\cdot (0.5) + (2p)^2 \\cdot (0.5)$$\n",
    "    \n",
    "    $$E[(E[Y | C])^2] = 1 \\cdot 0.5 + 4p^2 \\cdot 0.5$$\n",
    "    \n",
    "    $$E[(E[Y | C])^2] = 0.5 + 2p^2$$\n",
    "\n",
    "* Now, calculate the variance:\n",
    "\n",
    "    $$\\text{Var}(E[Y | C]) = E[(E[Y | C])^2] - (E[E[Y | C]])^2$$\n",
    "    \n",
    "    $$\\text{Var}(E[Y | C]) = (0.5 + 2p^2) - (0.5 + p)^2$$\n",
    "    \n",
    "    $$\\text{Var}(E[Y | C]) = 0.5 + 2p^2 - (0.25 + p + p^2)$$\n",
    "    \n",
    "    $$\\text{Var}(E[Y | C]) = 0.5 + 2p^2 - 0.25 - p - p^2$$\n",
    "    \n",
    "    $$\\text{Var}(E[Y | C]) = 0.25 - p + p^2$$\n",
    "\n",
    "### Step 4: Combine the Terms\n",
    "\n",
    "Now we add the two components according to the Law of Total Variance:\n",
    "\n",
    "$$\\text{Var}(Y) = E[\\text{Var}(Y | C)] + \\text{Var}(E[Y | C])$$\n",
    "\n",
    "$$\\text{Var}(Y) = (0.25 + p - p^2) + (0.25 - p + p^2)$$\n",
    "\n",
    "Notice how the terms involving $p$ and $p^2$ cancel out!\n",
    "\n",
    "$$\\text{Var}(Y) = 0.25 + 0.25 + (p - p) + (-p^2 + p^2)$$\n",
    "\n",
    "$$\\text{Var}(Y) = 0.5$$\n",
    "\n",
    "The variance $\\text{Var}(Y)$ is indeed $0.5$, regardless of the value of $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f52e29-37eb-4263-ae20-04242ceb3d73",
   "metadata": {},
   "source": [
    "### Intuition: Why Does $p$ Cancel Out?\n",
    "\n",
    "The cancellation happens because the two components of the total variance move in opposite directions as the bias $p$ changes:\n",
    "\n",
    "* **Average Within-Coin Variance ($E[\\text{Var}(Y | C)] = 0.25 + p(1-p)$):** This term represents the inherent randomness *within* each coin type. The variance of a single Bernoulli or Binomial trial is maximized when $p=0.5$. So, as the biased coin's $p$ moves away from 0.5 (towards 0 or 1), its individual variance $2p(1-p)$ *decreases*. This makes the *average* variance term smaller when $p$ is far from 0.5.\n",
    "\n",
    "* **Variance Between Coin Averages ($\\text{Var}(E[Y | C]) = 0.25 - p + p^2$):** This term represents how different the *average* outcomes are for the two coins. The expected values are $E[Y|C=F]=1$ and $E[Y|C=B]=2p$. When $p=0.5$, both expectations are 1, so there's *no variance* between them ($\\text{Var}(E[Y|C]) = 0.25 - 0.5 + 0.25 = 0$). As $p$ moves away from 0.5, the difference between the average outcomes (1 and 2p) *increases*, leading to a *larger* variance between the conditional expectations.\n",
    "\n",
    "These two effects perfectly offset each other. As the bias $p$ makes one term smaller, it makes the other term larger by exactly the same amount, keeping their sum constant at 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "338afeb8-9ef0-4e79-bac8-2bebafbe3526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_15.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define the range of p (bias of the second coin)\n",
    "p = np.linspace(0, 1, 200)\n",
    "\n",
    "# Calculate the two components of variance\n",
    "# E[Var(Y|C)] = 0.25 + p(1-p)\n",
    "avg_within_coin_variance = 0.25 + p * (1 - p)\n",
    "\n",
    "# Var(E[Y|C]) = 0.25 - p + p**2\n",
    "variance_between_coin_means = 0.25 - p + p**2\n",
    "\n",
    "# Calculate the total variance (sum of the two components)\n",
    "total_variance = avg_within_coin_variance + variance_between_coin_means\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the three lines with custom hover templates\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=p, \n",
    "        y=avg_within_coin_variance, \n",
    "        mode='lines', \n",
    "        name='E[Var(Y | C)] (Avg. Within-Coin Variance)',\n",
    "        line=dict(width=2, color='blue'),\n",
    "        hovertemplate='Bias p: %{x:.3f}<br>E[Var(Y|C)]: %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=p, \n",
    "        y=variance_between_coin_means, \n",
    "        mode='lines', \n",
    "        name='Var(E[Y | C]) (Variance Between Coin Means)',\n",
    "        line=dict(width=2, color='green'),\n",
    "        hovertemplate='Bias p: %{x:.3f}<br>Var(E[Y|C]): %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=p, \n",
    "        y=total_variance, \n",
    "        mode='lines', \n",
    "        name='Var(Y) (Total Variance)',\n",
    "        line=dict(width=3, dash='dash', color='black'),\n",
    "        hovertemplate='Bias p: %{x:.3f}<br>Total Variance: %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add a point for p=0.6 to highlight that specific case\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.6],\n",
    "        y=[0.5],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=10, color='red'),\n",
    "        text=[\"p=0.6\"],\n",
    "        textposition=\"top center\",\n",
    "        name=\"Biased Coin (p=0.6)\",\n",
    "        hovertemplate='Bias p: 0.6<br>Total Variance: 0.5<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add annotations for the variance components at p=0.6\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.6],\n",
    "        y=[0.25 + 0.6 * (1 - 0.6)],\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color='blue'),\n",
    "        name=\"Within-Coin at p=0.6\",\n",
    "        hovertemplate='E[Var(Y|C)] at p=0.6: %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.6],\n",
    "        y=[0.25 - 0.6 + 0.6**2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color='green'),\n",
    "        name=\"Between-Coin at p=0.6\",\n",
    "        hovertemplate='Var(E[Y|C]) at p=0.6: %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Components of Variance vs. Biased Coin Probability',\n",
    "    xaxis_title=\"Bias 'p' of the Second Coin (P(Heads))\",\n",
    "    yaxis_title='Variance Component',\n",
    "    yaxis=dict(range=[0, 0.6]),  # Set ylim to better see the components\n",
    "    legend=dict(y=1.0, x=1.9, xanchor='right'),\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=500,\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# Add grid\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "\n",
    "# Add shapes to highlight special cases\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=0.5, y0=0,\n",
    "    x1=0.5, y1=0.5,\n",
    "    line=dict(\n",
    "        color=\"gray\",\n",
    "        width=1,\n",
    "        dash=\"dot\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add annotation for the fair coin (p=0.5)\n",
    "fig.add_annotation(\n",
    "    x=0.5,\n",
    "    y=0.1,\n",
    "    text=\"Fair Coin (p=0.5)\",\n",
    "    showarrow=True,\n",
    "    arrowhead=2,\n",
    "    arrowsize=1,\n",
    "    arrowwidth=1,\n",
    "    ax=40\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b51f3-f932-4cec-b48f-acdad7c30581",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The constant variance of 0.5 in this coin mixture problem is a fascinating result that stems directly from the Law of Total Variance. While it seems paradoxical that the overall variability doesn't depend on the specific bias $p$ of the second coin, the mathematical breakdown shows a perfect cancellation effect. The average variance *within* the coin types and the variance *between* the coin types' average outcomes compensate for each other precisely.\n",
    "\n",
    "This example highlights how decomposing variance can reveal underlying structures and sometimes lead to surprising, constant results even when parameters within the mixture model are changing. It also serves as a reminder that our intuition about how probability distributions combine can sometimes be misleading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af1f2b-b4f2-4dd0-843e-c1eeaea9b546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
